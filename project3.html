<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- SEO -->
    <meta name="description" content="Overview of an AI coding project">
    <meta name="keywords" content="James Elia, project, project3, generative-AI, AI, python, stable-diffusion, evolution">
    <meta name="author" content="James L. Elia">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://www.jlelia.net/project3">

    <!-- Site Icons -->
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Project #3 – James L. Elia">
    <meta property="og:description" content="Description of personal website project">
    <meta property="og:image" content="https://www.jlelia.net/images/initialSet.webp">
    <meta property="og:url" content="https://www.jlelia.net/project3">
    <meta property="og:type" content="website">

    <!-- PWA / Mobile Enhancements -->
    <link rel="manifest" href="/site.webmanifest">
    <meta name="theme-color" content="#ffffff">

  <!-- Performance Optimizations -->
  <link rel="preload" as="image" href="/images/headshot.webp" imagesrcset="/images/headshot.webp 1x" fetchpriority="high">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/styles.css">

  <title>Project #3 - James L. Elia</title>
  </head>
  <body>
    <header>
      <div class="header-inner container">
  <div class="brand-group">
          <img src="/images/headshot.webp" alt="James L. Elia headshot" class="headshot" width="75" height="75">
          <h1>James L. Elia</h1>
        </div>
        <nav aria-label="Primary">
          <a href="/">Home</a>
          <a href="/about">About</a>
          <a href="/publications">Publications</a>
          <a href="/projects">Projects</a>
          <a href="/blog">Blog</a>
        </nav>
      </div>
    </header>
  
<main>
      <h2>Project #3: Aesthetic Selection - Evolutionary AI on HPC</h2>
      <h3><a href="https://github.com/jlelia/aesthetic_selection" target="_blank" rel="noopener noreferrer">GitHub Repo</a></h3>

      <div class="tech-stack">
        <p><strong>Stack:</strong> Python • PyTorch • Diffusers (SDXL) • Hugging Face Accelerate • HPC (Slurm) • X11 Forwarding</p>
      </div>

      <p>
        <strong>Objective</strong>: Demonstrate capability in deploying interactive, generative AI workflows on high-performance computing clusters by simulating biological evolution via "human-in-the-loop" selection.
      </p>
      <p>
        Presented at the 2025 Envisioning AI at Yale Symposium.
      </p>

      <h3>Generative AI as an Evolutionary System</h3>
      <p>
        To bridge the gap between machine learning and biology, I designed this pipeline to treat the latent space of a diffusion model as an evolutionary landscape. 
        The workflow rigorously maps biological first principles to computational parameters:
      </p>
      <ul>
          <li><strong>Genotype and Inheritance:</strong> The seed image acts as the genetic code. We use <code>img2img</code> generation to pass phenotypic traits to the next generation.</li>
          <li><strong>Mutation Rate:</strong> The denoising strength and guidance scale function as stochastic mutation. Too low and the species stagnates; too high and lineage is lost.</li>
          <li><strong>Selection Pressure:</strong> Symposium attendees acted as the environment. Using a custom voting interface, they applied selective pressure, determining which phenotypes survived to reproduce.</li>
      </ul>
      <p>
        We repeat this core loop, iteratively voting to create increasingly aesthetic images.
      </p>

      <h3>HPC Architecture and Headless Interaction</h3>
      <p>
        Running Stable Diffusion XL in near real-time requires VRAM-rich compute that exceeds standard local capabilities. I deployed this workflow on Yale’s 
        <strong>McCleary High-Performance Computing cluster</strong>, which presented unique engineering challenges regarding resource allocation and interactive visualization in a headless environment.
      </p>
      <p>
        To solve this, I engineered a <strong>decoupled architecture</strong> with help from Sam Friedman at Yale's Center for Research Computer:
      </p>
      <ul>
        <li><strong>Backend (Compute):</strong> A Python script utilizing <code>accelerate</code> and <code>xformers</code> handles heavy tensor operations and memory-efficient attention on A100 GPU nodes.</li>
        <li><strong>Frontend (Visualization):</strong> A lightweight viewer script utilizes <strong>X11 forwarding</strong> to project the generated gallery from the headless cluster directly to the local displays via SSH, allowing for real-time audience feedback loops.</li>
      </ul>

      <figure style="text-align: center;">
         <img src="/images/overviewPic.webp" alt="Three sets of three AI generated images showing evolutionary progression" class="content-image" loading="lazy">
         <figcaption>
           <strong>The Evolutionary Loop:</strong> Three iterations of three prompts compete. Images selected by the audience become the input for the next generation, creating a directed evolutionary path through the model's latent space.
         </figcaption>
      </figure>

      <div class="project-navigation">
        <a class="nav-left" href="/project2">← Project #2</a>
        <a class="nav-right" href="/projects">Project Hub →</a>
      </div>
    </main>
  
    <footer>
      <p>&copy; 2026 James L. Elia</p>
    </footer>
  </body>
</html>
