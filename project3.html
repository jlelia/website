<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- SEO -->
    <meta name="description" content="Overview of an AI coding project">
    <meta name="keywords" content="James Elia, project, project3, generative-AI, AI, python, stable-diffusion, evolution">
    <meta name="author" content="James L. Elia">
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://www.jlelia.net/project3">

    <!-- Site Icons -->
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Project #3 – James L. Elia">
    <meta property="og:description" content="Description of personal website project">
    <meta property="og:image" content="https://www.jlelia.net/images/initialSet.webp">
    <meta property="og:url" content="https://www.jlelia.net/project3">
    <meta property="og:type" content="website">

    <!-- PWA / Mobile Enhancements -->
    <link rel="manifest" href="/site.webmanifest">
    <meta name="theme-color" content="#ffffff">

  <!-- Performance Optimizations -->
  <link rel="preload" as="image" href="/images/headshot.webp" imagesrcset="/images/headshot.webp 1x" fetchpriority="high">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/styles.css">

  <title>Project #3 - James L. Elia</title>
  </head>
  <body>
    <header>
      <div class="header-inner container">
  <div class="brand-group">
          <img src="/images/headshot.webp" alt="James L. Elia headshot" class="headshot" width="75" height="75">
          <h1>James L. Elia</h1>
        </div>
        <nav aria-label="Primary">
          <a href="/">Home</a>
          <a href="/about">About</a>
          <a href="/publications">Publications</a>
          <a href="/projects">Projects</a>
          <a href="/blog">Blog</a>
        </nav>
      </div>
    </header>
  
<main>
      <h2>Project #3: Aesthetic Selection in AI Image Generation</h2>
      <h3><a href="https://github.com/jlelia/aesthetic_selection" target="_blank" rel="noopener">GitHub Repo</a></h3>

      <div class="tech-stack">
        <p><strong>Stack:</strong> HPC (Slurm) | Python 3 | PyTorch | Diffusers (SDXL) | Matplotlib | X11 Forwarding</p>
      </div>

      <p>
        <strong>Practical Objective</strong>: Create an interactive workshop for the 2025 Envisioning AI at Yale Symposium applying evolutionary principles to AI image generation.
      </p>
      <p>
        <strong>Learning Objective</strong>: Build fluency with high-performance computing and deployment of pre-built generative AI models.
      </p>

      <h3>Generative AI as an Evolutionary System</h3>
      <p>
        To bridge the gap between machine learning and biology, I designed this pipeline to treat the latent space of a diffusion model as an evolutionary landscape.
        The core loop of the exhibit:
      </p>
      <ul>
          <li><strong>txt2img:</strong> I feed in three prompts and generate three images each (nine total), displayed on a large television</li>
          <ul>
            <li>For example: "a beach at sunset", "a river in a mountain valley", "a futuristic cityscape at night"</li>
          </ul>
          <li><strong>Voting:</strong> Symposium attendees use a keyboard to vote for their favorite image in each category</li>
          <li><strong>img2img:</strong> Once an image reaches a vote threshold, it is fed into an img2img diffusion to create three new variants for that prompt</li>
      </ul>
      <p>
        As the loop continues, we theoretically generate increasingly pleasing images (at least, according to the crowd). We can map the parameters directly to evolutionary
        principles:
      </p>
      <ul>
          <li><strong>Genotype and Inheritance:</strong> The seed image acts as the genetic code. We use <code>img2img</code> generation to pass phenotypic traits to the next generation.</li>
          <li><strong>Mutation Rate:</strong> The denoising strength functions as the mutation rate. Too low and the image is visually identical; too high and the image loses its lineage.</li>
          <li><strong>Selection Pressure:</strong> Symposium attendees act as the environment. Using a voting interface, they applied selective pressure, determining which phenotypes survived to reproduce.</li>
      </ul>

      <h3>HPC Architecture and Headless Interaction</h3>
      <p>
        Running Stable Diffusion XL on several images in real-time requires VRAM-rich compute that exceeds standard local capabilities. I deployed this workflow on Yale’s 
        <strong>McCleary High-Performance Computing cluster</strong>, which presented unique engineering challenges regarding resource allocation and interactive visualization in a headless environment.
      </p>
      <p>
        While I built the backend, YCRC's Sam Friedman helped me set up X11 forwarding so attendees had an interactive display:
      </p>
      <ul>
        <li><strong>Backend (Compute):</strong> A Python script utilizing <code>accelerate</code> and <code>xformers</code> integrates heavy tensor operations and memory-efficient attention on A100 GPU nodes with the core logic described above.</li>
        <li><strong>Frontend (Visualization):</strong> A lightweight <strong>Matplotlib</strong> viewer script utilizes <strong>X11 forwarding</strong> to project the generated gallery from the headless cluster directly to the local displays via SSH, allowing for real-time audience feedback loops.</li>
      </ul>
      <p>
        The biggest engineering hurdle was dependency management. Getting the "shifting sands" of modern AI libraries to play nicely with the rigid environment of an HPC cluster was a crash course in dependency hell.
      </p>

      <figure style="text-align: center;">
         <img src="/images/overviewPic.webp" alt="Three sets of three AI generated images showing evolutionary progression" class="content-image" loading="lazy">
         <figcaption>
           <strong>The Evolutionary Loop:</strong> Three iterations of three prompts compete. Images selected by the audience become the input for the next generation, creating a directed evolutionary path through the model's latent space.
           Winners outlined with green.
         </figcaption>
      </figure>

      <div class="project-navigation">
        <a class="nav-left" href="/project2">← Project #2</a>
        <a class="nav-right" href="/project4">Project #4 →</a>
      </div>
    </main>
  
    <footer>
      <p>&copy; 2026 James L. Elia</p>
    </footer>
  </body>
</html>
